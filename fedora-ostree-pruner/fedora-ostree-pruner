#!/usr/bin/python3
# -*- coding: utf-8 -*-
#
# fedora-ostree-pruner - A utility to prune our Fedora ostree repos.
#
# Copyright (C) 2022 Red Hat, Inc.
# SPDX-License-Identifier:      GPL-2.0+
#
# Authors:
#     Dusty Mabe <dusty@dustymabe.com>

import argparse
import datetime
import logging
import os
import pprint
import subprocess
import time
import traceback


logformat = "%(asctime)s %(levelname)s %(name)s - %(message)s"
logging.basicConfig(level=logging.INFO, format=logformat)
logger = logging.getLogger('fedora-ostree-pruner')

# The location of our two unified ostree repos
OSTREECOMPOSEREPO = '/mnt/koji/compose/ostree/repo'
OSTREEPRODREPO = '/mnt/koji/ostree/repo'

FEDORA_STABLE_LIST = [41, 42, 43]
FEDORA_EOL_LIST = [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]

ATOMIC_HOST_ARCHES = ['x86_64', 'aarch64', 'ppc64le']
ATOMIC_ARCHES = ['x86_64', 'aarch64', 'ppc64le']
FEDORA_COREOS_ARCHES = ['x86_64', 'aarch64', 'ppc64le', 's390x']

ATOMIC_VARIANTS = ['cosmic-atomic', 'kinoite', 'onyx', 'sericea', 'silverblue']

# https://github.com/coreos/fedora-coreos-tracker/blob/main/stream-tooling.md#introduction
FEDORA_COREOS_PRODUCTION_STREAMS = ['next', 'testing', 'stable']

# The amount of time to retain commits in the compose repo for each branch
COMPOSE_REPO_POLICY = 'time:90'

# The policy for each ref in the prod repo. The following specifications are supported:
#   - delete       -> Delete the ref from the repo.
#   - None         -> No prune policy, don't prune anything.
#   - time:$time   -> Amount of time (in days) to keep content
#   - depth:$depth -> Depth of commit history to keep
PROD_REF_POLICIES = dict()
for arch in ATOMIC_ARCHES:
    for v in ATOMIC_VARIANTS:
        # Keep only the last 180 days of rawhide Atomic Desktops
        PROD_REF_POLICIES[f'fedora/rawhide/{arch}/{v}']     = 'time:180'
        # For Atomic Desktop variants keep all stable/updates (they are aliased).
        # For testing, keep just the last 90 days.
        for release in FEDORA_STABLE_LIST:
            PROD_REF_POLICIES[f'fedora/{release}/{arch}/{v}']         = None
            PROD_REF_POLICIES[f'fedora/{release}/{arch}/updates/{v}'] = None
            PROD_REF_POLICIES[f'fedora/{release}/{arch}/testing/{v}'] = 'time:90'
        # For EOL Atomic Desktop variants the updates ref and stable ref are aliased
        # so we'll keep 1 commit for both of those.
        for release in FEDORA_EOL_LIST:
            PROD_REF_POLICIES[f'fedora/{release}/{arch}/{v}']         = 'depth:0'
            PROD_REF_POLICIES[f'fedora/{release}/{arch}/updates/{v}'] = 'depth:0'
            PROD_REF_POLICIES[f'fedora/{release}/{arch}/testing/{v}'] = 'delete'
    # Delete any references to Atomic Workstation
    PROD_REF_POLICIES[f'fedora/rawhide/{arch}/workstation'] = 'delete'
    for release in FEDORA_EOL_LIST:
        PROD_REF_POLICIES[f'fedora/{release}/{arch}/workstation'] = 'delete'
        PROD_REF_POLICIES[f'fedora/{release}/{arch}/updates/workstation'] = 'delete'
        PROD_REF_POLICIES[f'fedora/{release}/{arch}/testing/workstation'] = 'delete'
for arch in ATOMIC_HOST_ARCHES:
    # Delete all atomic host rawhide
    PROD_REF_POLICIES[f'fedora/rawhide/{arch}/atomic-host'] = 'delete'
    # For EOL ATOMIC HOST we keep only the last commit on the stable ref
    for release in FEDORA_EOL_LIST:
        PROD_REF_POLICIES[f'fedora/{release}/{arch}/atomic-host']         = 'depth:0'
        PROD_REF_POLICIES[f'fedora/{release}/{arch}/updates/atomic-host'] = 'delete'
        PROD_REF_POLICIES[f'fedora/{release}/{arch}/testing/atomic-host'] = 'delete'
for arch in FEDORA_COREOS_ARCHES:
    # For production Fedora CoreOS Streams we don't prune anything right now
    for stream in FEDORA_COREOS_PRODUCTION_STREAMS:
        PROD_REF_POLICIES[f'fedora/{arch}/coreos/{stream}'] = None


def get_prod_refs():
    cmd = ['ostree', 'refs', '--repo', OSTREEPRODREPO]
    cp = runcmd(cmd, capture_output=True)
    return cp.stdout.decode('utf-8').splitlines()


def perform_repo_checks():
    # Error out if any refs exist that aren't defined in the policy
    prod_refs = get_prod_refs()
    errors = []
    for ref in prod_refs:
        if ref not in PROD_REF_POLICIES:
            errors.append(f'Ref {ref} in repo {OSTREEPRODREPO} but no policy defined.')
    if errors:
        for error in errors:
            logger.error(error)
        raise Exception("Found refs with no policy defined.")

    # Warn up front for refs that are in the policy but not in the repo
    for ref, policy in PROD_REF_POLICIES.items():
        if ref not in prod_refs:
            if policy != 'delete':
                logger.warning('Policy defined for a ref that is not in the'
                               f' repo {OSTREEPRODREPO}: {ref}')
            continue


def catch_exceptions_and_continue(func):
    # This is a decorator function that will re-call the decorated
    # function and will catch any exceptions and not raise them further.
    # We want to do this because if we raise exceptions it will cause
    # the process to exit and we'll lose the traceback logs from the
    # container.
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error('Caught Exception!')
            logger.error('###################################')
            traceback.print_exc()
            logger.error('###################################')
            logger.error('\t continuing...')
            pass
    return wrapper


# Beneath this is code, no config needed here
def runcmd(cmd: list, **kwargs: int) -> subprocess.CompletedProcess:
    # Default to not capture output, check=True, shell=False
    if 'capture_output' not in kwargs:
        kwargs['capture_output'] = False
    if 'check' not in kwargs:
        kwargs['check'] = True
    if 'shell' not in kwargs:
        kwargs['shell'] = False
    try:
        logger.info(f'Running command: {cmd}')
        cp = subprocess.run(cmd, **kwargs)
    except subprocess.CalledProcessError as e:
        logger.error(f'Running command returned bad exitcode: {e.returncode}')
        logger.error(f'COMMAND: {cmd}')
        if kwargs['capture_output']:
            logger.error(f' STDOUT: {e.stdout}')
            logger.error(f' STDERR: {e.stderr}')
        raise e
    return cp  # subprocess.CompletedProcess


def pruning_policy_to_args(policy: str):
    # parse the given policy statement and return the command
    # that should be run
    if policy.startswith('depth:'):
        number = policy[6:]
        return f'--depth={number}'
    if policy.startswith('time:'):
        number = policy[5:]
        return f'--keep-younger-than={number} days ago'
    assert False, f"Invalid policy string '{policy}'"


def delete_ref_in_repo(ref: str, repo: str, test: bool):
    logger.info(f'Deleting the {ref} ref in repo {repo}.')
    if test:
        logger.info('Skipping delete because of test mode')
        return

    # Delete the ref. We don't worry about pruning here as we'll
    # run a generic prune for unreachable objects afterwards
    cmd = ['ostree', 'refs', '--repo', repo, '--delete', ref]
    runcmd(cmd)

    # Update the summary file since we deleted a ref
    cmd = ['ostree', 'summary', '--repo', repo, '-u']
    runcmd(cmd)


@catch_exceptions_and_continue
def prune_compose_repo(test=False):
    # prune the compose repo
    logger.info(f'Pruning the compose repo {OSTREECOMPOSEREPO}'
                f' with policy {COMPOSE_REPO_POLICY}')
    prunearg = pruning_policy_to_args(COMPOSE_REPO_POLICY)
    cmd = ['ostree', 'prune', '--repo', OSTREECOMPOSEREPO,
           '--refs-only', prunearg]
    if test:
        cmd.append('--no-prune')
    runcmd(cmd)


@catch_exceptions_and_continue
def prune_prod_repo(test=False):
    # Perform repo checks again right before prune
    perform_repo_checks()
    prod_refs = get_prod_refs()

    # prune each branch in the policy with specified value
    for ref,policy in PROD_REF_POLICIES.items():

        # Skip if there is no ref in the repo for this policy
        if ref not in prod_refs:
            continue

        if policy is None:
            logger.info(f'Skipping ref {ref} in repo {OSTREEPRODREPO}.'
                        ' Policy is to keep all commits.')
            continue

        # Detect if the ref is an alias (they are symlinks) and skip if so.
        if os.path.islink(f'{OSTREEPRODREPO}/refs/heads/{ref}'):
            logger.info(f'Skipping operations on alias {ref} in repo {OSTREEPRODREPO}.')
            continue

        if policy == 'delete':
            delete_ref_in_repo(ref, OSTREEPRODREPO, test)
            continue

        prunearg = pruning_policy_to_args(policy)

        logger.info(f'Pruning the {ref} ref in repo {OSTREEPRODREPO} to {policy}')
        # Use --commit-only so only the commit gets deleted and not related objects
        # which take time to calculate reachability. We go through and first delete
        # commits (fast) and then go back at the end and run a single generic delete
        # prune of any unreachable objects in the repo (slow).
        cmd = ['ostree', 'prune', '--repo', OSTREEPRODREPO,
               '--commit-only', '--only-branch', ref, '--refs-only', prunearg]
        if test:
            cmd.append('--no-prune')
        runcmd(cmd)

    # Now run a generic prune once over the entire repo to delete any
    # objects in the repo that aren't reachable. This should save some
    # time since we only iterate over the entire repo once, versus for
    # every ref/commit we deleted.
    cmd = ['ostree', 'prune', '--repo', OSTREEPRODREPO, '--refs-only']
    if test:
        cmd.append('--no-prune')
    runcmd(cmd)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--test",
                        help="Don't actually prune", action='store_true')
    parser.add_argument("--loop",
                        help="Loop forever, run once a week.", action='store_true')
    args = parser.parse_args()

    # on startup let's print out the config that was generated
    logger.info('The configured policy is: \n%s' %
                pprint.pformat(PROD_REF_POLICIES, indent=8))

    # Configure a umask of 0002 which will allow for the group permissions
    # to include write for newly created files. We need this because we'd
    # like to access the OSTree repos from two different Kubernetes pods,
    # which will have different UIDs but the same GID.
    # See https://pagure.io/releng/issue/8811#comment-616490
    os.umask(0o0002)

    # Perform repo checks on initial startup
    perform_repo_checks()

    # If we were asked to run in a loop, then run once a week on
    # Saturday.
    days = "Monday Tuesday Wednesday Thursday Friday Saturday Sunday".split()
    if args.loop:
        while True:
            # If it's Saturday, run the prune
            day = days[datetime.date.today().weekday()]
            if day == 'Saturday':
                prune_compose_repo(args.test)
                prune_prod_repo(args.test)
                logger.info(f"Finished pruning operations.")
            else:
                logger.info(f"Today is {day}. Sleeping...")
            time.sleep(60*60*24)  # 24h
    else:
        prune_compose_repo(args.test)
        prune_prod_repo(args.test)



if __name__ == '__main__':
    main()
